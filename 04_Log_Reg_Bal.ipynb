{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Partial Discharge\n",
    "## Julian Sweet DSI-LA-6\n",
    "## Notebook 4 -Logisitic Regression Modeling, Balanced Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding notebooks the Kaggle PD training data was manipulated to make a pair of data sets with both balanced and unbalanced classes.\n",
    "\n",
    "The original data was then visualized as both time-domain as well as frequency-domain data.\n",
    "\n",
    "Before proceeding, it is important to emphasize what can and cannot be modelled given finite storage and computer memory contraints.\n",
    "\n",
    "To model the time-domain data, even using the smaller balanced classes subset, is not possible at this time. This smaller balanced class subset is composed of 840 rows (observations) of labelled training. However, the columns of each observation represent 800,000 feature by which a model would be expected to compute over.\n",
    "\n",
    "Attempts were made using a Macbook Pro with 8 GB of RAM, a desktop home workstation with 32GB of RAM, as well as a high-powered GPU instance from AWS with 61GB of RAM. Even with the smallest data set of 840 rows by 800k columns. Kernal overflow was inevitable. Obviously the same problem exists with the STFT data it too is composed of over 800k of columns per observation.\n",
    "\n",
    "Downsampling of time-domain or STFT data should be explored. However, moving forward all modeling is presented below is for FFT data whereby each row (observation) is only 256 columns in length, which is 2^8 and less than resolution utilized during intial EDA, but still a considerable feature set.\n",
    "\n",
    "Modeling will begin with the smallest of the two, the balanced class dataset of 1050 rows (80 / 20 train test split) by 1024 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import resample, stft\n",
    "from sys import getsizeof\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.95 ms, sys: 2.73 ms, total: 5.68 ms\n",
      "Wall time: 4.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#X_train_resamp_data = np.load('./npy_datasets/X_train_resamp_data.npy')\n",
    "#X_test_resamp_data  = np.load('./npy_datasets/X_test_resamp_data.npy')\n",
    "y_test_resamp       = np.load('./npy_datasets/y_test_resamp.npy')\n",
    "y_train_resamp      = np.load('./npy_datasets/y_train_resamp.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick to load, but untenable by any model I tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((840, 800000), (210, 800000), (210,), (840,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resamp_data.shape, X_test_resamp_data.shape, y_test_resamp.shape, y_train_resamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliansweet/anaconda3/lib/python3.6/site-packages/scipy/fftpack/basic.py:153: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  x = x[index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.26 s, sys: 5.32 s, total: 7.58 s\n",
      "Wall time: 9.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_fft = 256\n",
    "X_train_fft = np.abs(fft(X_train_resamp_data, n_fft))\n",
    "X_test_fft  = np.abs(fft(X_test_resamp_data, n_fft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((840, 256), (210, 256))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fft.shape, X_test_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./npy_datasets/X_train_bal_fft', X_train_fft) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./npy_datasets/X_test_bal_fft', X_test_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fft = np.load('./npy_datasets/X_train_bal_fft.npy')\n",
    "X_test_fft  = np.load('./npy_datasets/X_test_bal_fft.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling will begin with Linear / Logistic Regression / Classification. It is the simplest, the most human interpretable machine model. Regression should always be attempted unless dataset specfics dictate that another model is optimal.\n",
    "\n",
    "The code below specifies try try both types of regularization and at least initially, will score with accuracy.\n",
    "\n",
    "6 processor jobs refers to 4 cores being multithreaded constituting 8 virtual cores total. However, using all 8 will make the computer unusable during processing. Holding back two virual cores (one real) ensures computer usability. \n",
    "\n",
    "This model will be cross validated 5 times. Verbose level of any number greater than 1 maximizes verbosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {\n",
    "    'penalty' : ['l1', 'l2']\n",
    "    }\n",
    "\n",
    "logr1 = GridSearchCV(LogisticRegression(max_iter = 35000), \n",
    "                           n_jobs = 6, \n",
    "                           verbose = 2,\n",
    "                           scoring = 'accuracy',\n",
    "                           param_grid = params1,\n",
    "                           cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  10 | elapsed:    1.6s remaining:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
      "/Users/juliansweet/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr1.fit(X_train_fft, y_train_resamp)\n",
    "logr1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8083333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr1.score(np.abs(X_train_fft), y_train_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr1.score(np.abs(X_test_fft), y_test_resamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not overfit, also able to give a signifcantly better answer on than the naive baseline for balanced classes of 50% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\n",
    "    'penalty' : ['l1', 'l2']\n",
    "    }\n",
    "\n",
    "logr2 = GridSearchCV(LogisticRegression(max_iter = 35000), \n",
    "                           n_jobs = 6, \n",
    "                           verbose = 2,\n",
    "                           scoring = 'roc_auc',\n",
    "                           param_grid = params2,\n",
    "                           cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   5 out of  10 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  10 out of  10 | elapsed:    0.7s finished\n",
      "/Users/juliansweet/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr2.fit(np.abs(X_train_fft), y_train_resamp)\n",
    "logr2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930668934240362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr2.score(X_train_fft, y_train_resamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8384580498866213"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr2.score(X_test_fft, y_test_resamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is still overfit, but much better than the naive baseline.\n",
    "\n",
    "Changing the scoring mechanism during the fit also means that the .score method now returns \"roc_auc\" and not \"accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035714285714286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train_resamp, logr2.predict(X_train_fft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a confusion matrix. SKLearn exchanges the labelling convention, so this will create a dataframe of what the model guessed and what was the correct answer with explicit labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'predictions': logr2.predict(X_test_fft), 'actual': y_test_resamp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions  actual\n",
       "0            1       1\n",
       "1            0       1\n",
       "2            1       1\n",
       "3            1       1\n",
       "4            1       1\n",
       "5            1       1\n",
       "6            0       1\n",
       "7            1       1\n",
       "8            1       1\n",
       "9            0       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = df = pd.DataFrame(data = d)\n",
    "con.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(con['actual'], con['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the confusion matrix, true positive, true negative down the diagonal. False positive top right, false negative bottom left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83, 22],\n",
       "       [28, 77]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(con['actual'], con['predictions']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 22, 28, 77)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.79047619, 0.20952381],\n",
       "       [0.26666667, 0.73333333]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C / C.astype(np.float).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity = .733 / (.733 + .266) = .73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.217052e-02</td>\n",
       "      <td>0.957829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.747590e-01</td>\n",
       "      <td>0.425241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.804192e-09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.907145e-01</td>\n",
       "      <td>0.709286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.930036e-02</td>\n",
       "      <td>0.930700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0  4.217052e-02  0.957829\n",
       "1  5.747590e-01  0.425241\n",
       "2  8.804192e-09  1.000000\n",
       "3  2.907145e-01  0.709286\n",
       "4  6.930036e-02  0.930700"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(logr2.predict_proba(X_test_fft))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_guess = df[1] >= .40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test_resamp, biased_guess).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 28, 21, 84)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sensitivity = .8 / (.8 + .2) = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This skewing of the AUC ROC curve decreases True Negative and increases False Positive, but has benefit of greatly decreasing False Negative and increasing True Positive. Sensitivity is increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook #5 will now perform logistic regression analysis, but with the larger anomalous / unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
